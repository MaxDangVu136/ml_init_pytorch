{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Yc1muV0Swdqr",
        "4YjQMTTenhxZ"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **PyTorch tutorial: Brain tumour classification**"
      ],
      "metadata": {
        "id": "ycPa6VxFv6zk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning outcomes:\n",
        "*   Train a basic machine learning model using PyTorch.\n",
        "*   Have an appreciation for the steps taken in a machine learning workflow of an AI research project.\n",
        "\n"
      ],
      "metadata": {
        "id": "a_4Tfc6MwLq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "m3A44OJAwQWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import necessary libraries**"
      ],
      "metadata": {
        "id": "kwfr_jHUTorP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import os\n",
        "import torch\n",
        "import shutil\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from skimage import io, transform\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch import nn\n",
        "from torch.optim import AdamW\n",
        "from torch.optim import lr_scheduler"
      ],
      "metadata": {
        "id": "G31NmXB-iYfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data**"
      ],
      "metadata": {
        "id": "_4l53UDFneKS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Dataset"
      ],
      "metadata": {
        "id": "Bh63DV8ni1AI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is downloaded from [figshare](https://figshare.com/articles/dataset/brain_tumor_dataset/1512427).\n",
        "\n",
        "This brain tumor dataset containing 3064 T1 MRIs from 233 patients with three kinds of brain tumor: Meningioma (708 slices), Glioma (1426 slices), Pituitary tumor (930 slices).\n",
        "\n",
        "This data is organized in matlab data format (.mat file). Each file stores a struct containing the following fields for an image:\n",
        "*   cjdata.label:\n",
        "    *   1 for meningioma\n",
        "    *   2 for glioma\n",
        "    *   3 for pituitary tumor.\n",
        "*   cjdata.PID: patient ID.\n",
        "*   cjdata.image: image data.\n",
        "*   cjdata.tumorBorder: a vector storing the coordinates of discrete points on tumor border.\n",
        "*   cjdata.tumorMask: a binary image with 1s indicating tumor region.\n",
        "\n",
        "Only image and tumorMask are used in this project."
      ],
      "metadata": {
        "id": "Ybb32tMgjQH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset folder in /content/ folder\n",
        "!mkdir /content/brain_tumour_dataset/\n",
        "!mkdir /content/brain_tumour_dataset/BrainTumorData/\n",
        "\n",
        "# Download dataset from figshare\n",
        "!wget https://figshare.com/ndownloader/files/3381290/brainTumorDataPublic_1-766.zip https://figshare.com/ndownloader/files/3381293/brainTumorDataPublic_1533-2298.zip https://figshare.com/ndownloader/files/3381296/brainTumorDataPublic_767-1532.zip https://figshare.com/ndownloader/files/3381302/brainTumorDataPublic_2299-3064.zip\n",
        "!unzip /content/'*.zip*' -d /content/brain_tumour_dataset/BrainTumorData/"
      ],
      "metadata": {
        "id": "CCmWAEQRUiTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data visualization"
      ],
      "metadata": {
        "id": "FfJkoKmbjCoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize 4 images and their correspondnig mask."
      ],
      "metadata": {
        "id": "lEOc71SqTUqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ncol = 4\n",
        "rand_ndx = random.sample(range(0, 3065), ncol)\n",
        "fig, ax = plt.subplots(nrows=3,  ncols=ncol, figsize=(20, 10))\n",
        "i = 0\n",
        "for n in rand_ndx:\n",
        "  file = h5py.File(r\"/content/brain_tumour_dataset/BrainTumorData/\"+\n",
        "                   str(n)+'.mat','r').get('cjdata')\n",
        "  ax[0][i].imshow(file.get('image')[()],cmap='gray')\n",
        "  ax[0][i].imshow(file.get('tumorMask')[()],cmap='gray', alpha=0.3)\n",
        "  ax[0][i].set_title('Overlay')\n",
        "  ax[1][i].imshow(file.get('image')[()],cmap='gray')\n",
        "  ax[1][i].set_title('Image')\n",
        "  ax[2][i].imshow(file.get('tumorMask')[()],cmap='gray')\n",
        "  ax[2][i].set_title('Mask')\n",
        "  i+=1"
      ],
      "metadata": {
        "id": "FseACGnjjHmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset class"
      ],
      "metadata": {
        "id": "o957B1Vlj219"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a [custom Dataset class](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html).\n",
        "\n",
        "The 2 most important methods to override from the Pytorch Dataset class are:\n",
        "*   \\__len__ so that len(dataset) returns the size of the dataset.\n",
        "*   \\__getitem__ to support the indexing such that dataset[i] can be used to get *ith* sample.\n",
        "\n",
        "To avoid loading all the images at once, we initialize the dataset with the paths to the images and load them only when \\__getitem__ is called (through the dataloader).\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_aiY1I2ovjCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BrainMRIDataset(Dataset):\n",
        "    \"\"\"Brain MRI dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.images = os.listdir(self.root_dir)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        filename = os.path.join(self.root_dir,self.images[idx])\n",
        "        file = h5py.File(filename,'r').get('cjdata')\n",
        "        image = file.get('image')[()]\n",
        "        mask = file.get('tumorMask')[()]\n",
        "\n",
        "        sample = {'image': image, 'mask': mask}\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "id": "0WlZsM9nFCOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transform class"
      ],
      "metadata": {
        "id": "xMU9jg9kXa1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The transforms help to preprocess the data so that it fits the model inputs format.\n",
        "\n",
        "They can also be used for data augmentation (crop, rotation, etc).\n",
        "\n",
        "In this project, we create a resize transform and a 'toTensor' transform to go from numpy arrays to tensors as expected by the model.\n"
      ],
      "metadata": {
        "id": "kO_fy7ozUUTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Resize(object):\n",
        "    \"\"\"Resize the image and mask.\n",
        "\n",
        "    Args:\n",
        "        output_size (tuple or int): Desired output size. If tuple, output is\n",
        "            matched to output_size. If int, smaller of image edges is matched\n",
        "            to output_size keeping aspect ratio the same.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image = sample['image']\n",
        "        mask = sample['mask']\n",
        "\n",
        "        h, w = image.shape[:2]\n",
        "        if isinstance(self.output_size, int):\n",
        "            if h > w:\n",
        "                new_h, new_w = self.output_size * h / w, self.output_size\n",
        "            else:\n",
        "                new_h, new_w = self.output_size, self.output_size * w / h\n",
        "        else:\n",
        "            new_h, new_w = self.output_size\n",
        "\n",
        "        new_h, new_w = int(new_h), int(new_w)\n",
        "\n",
        "        image = transform.resize(image, (new_h, new_w)) * 255.0\n",
        "        image = np.stack((image,) * 3, axis=-1)\n",
        "        mask = transform.resize(mask, (new_h, new_w)) * 255.0\n",
        "        mask = np.expand_dims(mask,axis=-1)\n",
        "\n",
        "        sample['image'] = image\n",
        "        sample['mask'] = mask\n",
        "\n",
        "        return sample\n",
        "\n",
        "class ToTensor(object):\n",
        "    \"\"\"Convert ndarrays to Tensors.\"\"\"\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        # swap color axis because\n",
        "        # numpy image: H x W x C\n",
        "        # torch image: C x H x W\n",
        "        image = sample['image'].transpose((2, 0, 1))\n",
        "        mask = sample['mask'].transpose((2, 0, 1))\n",
        "        sample['image'] = torch.from_numpy(image)\n",
        "        sample['mask'] = torch.from_numpy(mask)\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "id": "WdPmMZDMHAym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Data and create Data sets"
      ],
      "metadata": {
        "id": "Yc1muV0Swdqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In deep learning, 3 sets are needed: train, test, and validation. We use the train_test_split function from sklearn library two times to split the data. The split is done on the path to images.\n",
        "\n",
        "[Reminder on data split](https://medium.com/syntaxerrorpub/understanding-the-difference-between-training-test-and-validation-sets-in-machine-learning-c59feec6483b#:~:text=In%20summary%2C%20training%2C%20testing%2C,model%20selection%20and%20hyperparameter%20tuning.): 'The training set is used to train the model; the test set evaluates its performance on unseen data; and the validation set aids in model selection and hyperparameter tuning.'"
      ],
      "metadata": {
        "id": "VLn-bhYbwkMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_files = os.listdir(\"/content/brain_tumour_dataset/BrainTumorData/\")\n",
        "\n",
        "# Split train and test data\n",
        "train_data, test_data = train_test_split(all_files, test_size = 0.1, random_state=123)\n",
        "\n",
        "# Split train and validation data\n",
        "train_data, val_data = train_test_split(train_data, test_size = 0.2, random_state=123)"
      ],
      "metadata": {
        "id": "ZyZyeEsmpG7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we create the 3 split folders and move images accordingly."
      ],
      "metadata": {
        "id": "wpZvfo5GYYhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = '/content/brain_tumour_dataset/BrainTumorData/'\n",
        "\n",
        "# Create train folder\n",
        "os.makedirs(os.path.join(root_dir, 'train'), exist_ok=True)\n",
        "for train_file in train_data:\n",
        "  shutil.move(os.path.join(root_dir, train_file), os.path.join(root_dir, 'train', train_file))\n",
        "\n",
        "# Create validation folder\n",
        "os.makedirs(os.path.join(root_dir, 'val'), exist_ok=True)\n",
        "for val_file in val_data:\n",
        "  shutil.move(os.path.join(root_dir, val_file), os.path.join(root_dir, 'val', val_file))\n",
        "\n",
        "# Create test folder\n",
        "os.makedirs(os.path.join(root_dir, 'test'), exist_ok=True)\n",
        "for test_file in test_data:\n",
        "  shutil.move(os.path.join(root_dir, test_file), os.path.join(root_dir, 'test', test_file))"
      ],
      "metadata": {
        "id": "ShVKqzwAKD6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we create 3 dataset instances passing the path to the corresponding folder and the previous mentionned transforms.\n",
        "\n",
        "*transforms.Compose* enables to run the transforms sequentially on the data."
      ],
      "metadata": {
        "id": "v5lDl7ArYW2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train dataset\n",
        "train_dataset = BrainMRIDataset(\n",
        "    root_dir='/content/brain_tumour_dataset/BrainTumorData/train',\n",
        "    transform=transforms.Compose([Resize(256), ToTensor()]))\n",
        "\n",
        "# Create validation dataset\n",
        "val_dataset = BrainMRIDataset(\n",
        "    root_dir='/content/brain_tumour_dataset/BrainTumorData/val',\n",
        "    transform=transforms.Compose([Resize(256), ToTensor()]))\n",
        "\n",
        "# Create test dataset\n",
        "test_dataset = BrainMRIDataset(\n",
        "    root_dir='/content/brain_tumour_dataset/BrainTumorData/test',\n",
        "    transform=transforms.Compose([Resize(256), ToTensor()]))"
      ],
      "metadata": {
        "id": "7eZX92HEIzuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loaders"
      ],
      "metadata": {
        "id": "4YjQMTTenhxZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset objects are used to create the data loaders. The default DataLoader class from Pytorch is used with batch size 4 (i.e passing 4 images at a time to the network).\n",
        "\n",
        "*Shuffle* is set to *True* for the train loader to mix the dataset."
      ],
      "metadata": {
        "id": "xn1by5lyxtfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,batch_size= 4, num_workers=2, shuffle=True)"
      ],
      "metadata": {
        "id": "xDfnlyPFxbm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test data\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,batch_size= 4, num_workers=2, shuffle=False)"
      ],
      "metadata": {
        "id": "KNs4KSAVzWyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation data\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,batch_size= 4, num_workers=2, shuffle=False)"
      ],
      "metadata": {
        "id": "5FwbFgLmzWnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model**"
      ],
      "metadata": {
        "id": "NvAS1MTlzzkc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Torch hub provides a [U-Net model](https://pytorch.org/hub/mateuszbuda_brain-segmentation-pytorch_unet/) with pretrained weights for brain MRI."
      ],
      "metadata": {
        "id": "i5olfsZj1y5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
        "    in_channels=3, out_channels=1, init_features=32, pretrained=True)"
      ],
      "metadata": {
        "id": "yGWAJc-E6Td3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is sent to GPU if available to speed the calculations."
      ],
      "metadata": {
        "id": "vJC4568tZy3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "9CGRZBL9HEVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loss**"
      ],
      "metadata": {
        "id": "R2IPEq5mnkiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We combine the DICE and BCE losses into the criterion we want to minimize during training. More information on losses choice can be found [here](https://www.linkedin.com/pulse/in-depth-exploration-loss-functions-deep-learning-kiran-dev-yadav/)."
      ],
      "metadata": {
        "id": "3THHaXKsaMBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_loss(inputs, target):\n",
        "    num = target.size(0)\n",
        "    inputs = inputs.reshape(num, -1)\n",
        "    target = target.reshape(num, -1)\n",
        "    smooth = 1.0\n",
        "    intersection = (inputs * target)\n",
        "    dice = (2. * intersection.sum(1) + smooth) / (inputs.sum(1) + target.sum(1) + smooth)\n",
        "    dice = 1 - dice.sum() / num\n",
        "    return dice\n",
        "\n",
        "def bce_dice_loss(inputs, target):\n",
        "    dicescore = dice_loss(inputs, target)\n",
        "    bcescore = nn.BCELoss()\n",
        "    bceloss = bcescore(inputs, target)\n",
        "\n",
        "    return bceloss + dicescore"
      ],
      "metadata": {
        "id": "BYgdLTKSG2QQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = bce_dice_loss"
      ],
      "metadata": {
        "id": "s_ho-SCoG56I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Optimizer**"
      ],
      "metadata": {
        "id": "JIGJ8lcHHLRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The AdamW optimizer is used for backpropagation as well as a learning rate scheduler that will reduce the learning rate every 5 steps with a coefficient of 0.5."
      ],
      "metadata": {
        "id": "hai6vExbbdDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), 0.1)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
      ],
      "metadata": {
        "id": "H-1LAG1wHBj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "8fdSf6ODHaYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, the loss histories are created and the best loss is set to infinite."
      ],
      "metadata": {
        "id": "vDzTI1YFb8ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_history = []\n",
        "loss_history_val = []\n",
        "best_loss_val = float('inf')"
      ],
      "metadata": {
        "id": "pFBteuBVHCTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We train the model for 30 epochs. At eahc step, the model is saved at /content/best_model.pth if the validation is smaller than the one from previous step."
      ],
      "metadata": {
        "id": "tZhZmMVqcFMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Start train…\")\n",
        "\n",
        "for epoch in range(30):\n",
        "   #Train mode\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    loss_running = []\n",
        "    for j, sample in enumerate(train_dataloader):\n",
        "        x, y = sample['image'].float().to(device), sample['mask'].float().to(device)\n",
        "\n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        loss_running.append(loss.item())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    loss_history.append(np.mean(loss_running))\n",
        "\n",
        "    # Evaluate mode\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        loss_val_running = []\n",
        "        for _, sample in enumerate(val_dataloader):\n",
        "            x_val, y_val = sample['image'].float().to(device), sample['mask'].float().to(device)\n",
        "            pred_val = model.forward(x_val) #pred_val = model(x_val)\n",
        "            loss_val= criterion(pred_val, y_val)\n",
        "            loss_val_running.append(loss_val.item())\n",
        "\n",
        "    curr_loss_val = np.mean(loss_val_running)\n",
        "    loss_history_val.append(curr_loss_val)\n",
        "\n",
        "    # Save the best weights\n",
        "    if curr_loss_val < best_loss_val:\n",
        "        best_loss_val = curr_loss_val\n",
        "        torch.save(model.state_dict(), r'/content/best_model.pth')\n",
        "\n",
        "    # Change the learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    # Print the results\n",
        "    print(\"epoch\", epoch,\n",
        "          \"train loss\", loss_history[-1],\n",
        "          \"val loss\", loss_history_val[-1],\n",
        "          \"epoch duration\", time.time()-start_time)"
      ],
      "metadata": {
        "id": "QxdhYhXAHlB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the losses graph."
      ],
      "metadata": {
        "id": "0da6KSzbeFWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 7))\n",
        "plt.plot(loss_history, label='train loss')\n",
        "plt.plot(loss_history_val, label='val loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "6jFnbKmqeHoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference**"
      ],
      "metadata": {
        "id": "Zd6mp9I3nuXf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best model weights can now be load and use to predict the mask of test images (unseen during training).\n",
        "\n"
      ],
      "metadata": {
        "id": "Pte89Ypkcl6f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load best model weights"
      ],
      "metadata": {
        "id": "IgbOJp_fc4wQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load('/content/best_model.pth',\n",
        "                        map_location=torch.device('cpu'))\n",
        "model.load_state_dict(checkpoint)"
      ],
      "metadata": {
        "id": "xub5Bd_Dnv83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "id": "OmvNTuKYc7B7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize 4 random images and their predicted and groundtruth masks from the test set."
      ],
      "metadata": {
        "id": "623pEbePdMOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_mask(mask_3d_array, scan, axx, title):\n",
        "    mask_cpu = mask_3d_array.cpu().detach().numpy()[0]\n",
        "    scan_cpu = scan.cpu().detach().numpy()[0]\n",
        "    axx.imshow(scan_cpu, cmap='gray')\n",
        "    axx.imshow(np.round(mask_cpu), cmap='gray', alpha=0.5)\n",
        "    axx.set_title(title)"
      ],
      "metadata": {
        "id": "qQV9bLtSn9uD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = test_dataloader\n",
        "ncol = 4\n",
        "rand_ndx = random.sample(range(0, len(dataloader)), ncol)\n",
        "fig, ax = plt.subplots(nrows=2,  ncols=ncol, figsize=(20, 10))\n",
        "i = 0\n",
        "for n, sample in enumerate(dataloader):\n",
        "    x, y = sample['image'].float().to(device), sample['mask'].float().to(device)\n",
        "    if n in rand_ndx:\n",
        "        pred = model.forward(x)\n",
        "        plot_mask(pred[0], x[0], ax[0][i], 'Prediction')\n",
        "        plot_mask(y[0], x[0], ax[1][i], 'Groundtruth')\n",
        "        i+=1"
      ],
      "metadata": {
        "id": "h726FM-DPXOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy"
      ],
      "metadata": {
        "id": "5AoqqPhnc9j5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define the dice_metric function to compute accuracy of the model after training."
      ],
      "metadata": {
        "id": "llrWFp5_eAc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_metric(inputs, target):\n",
        "    intersection = 2.0 * (target * inputs).sum()\n",
        "    union = target.sum() + inputs.sum()\n",
        "    if target.sum() == 0 and inputs.sum() == 0:\n",
        "        return 1.0\n",
        "\n",
        "    return intersection / union"
      ],
      "metadata": {
        "id": "wmS1JOEPdyyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_acc(dataloader, model):\n",
        "    acc = []\n",
        "    loss = []\n",
        "    #model.eval()\n",
        "    #with torch.no_grad():\n",
        "    for _, sample in enumerate(dataloader):\n",
        "        x, y = sample['image'].float().to(device), sample['mask'].float().to(device)\n",
        "        pred = model(x)\n",
        "        acc.append(dice_metric(pred.data.cpu().numpy(), y.data.cpu().numpy()))\n",
        "\n",
        "    return np.mean(acc)"
      ],
      "metadata": {
        "id": "XKWjIjWAdzUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We compute the accuracy on each dataset. The accuracy on the test set should be used as a reference to assess the model performance."
      ],
      "metadata": {
        "id": "FUBNr7pEeYP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train set\n",
        "acc_train = compute_acc(train_dataloader, model)\n",
        "print(f'Acccuracy on the train set is {acc_train}')"
      ],
      "metadata": {
        "id": "8CEoK4HqeXpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation set\n",
        "acc_val = compute_acc(val_dataloader, model)\n",
        "print(f'Acccuracy on the train set is {acc_val}')"
      ],
      "metadata": {
        "id": "71STqVcofSuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test set\n",
        "acc_test = compute_acc(test_dataloader, model)\n",
        "print(f'Acccuracy on the train set is {acc_test}')"
      ],
      "metadata": {
        "id": "waRjEuAofSjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Acknowledgement:\n",
        "\n",
        "*   https://github.com/seyma-tas/Brain-Tumor-Segmentation-Project/blob/master/2AdamW_DICE_BrainTumorGenesis.ipynb\n",
        "\n"
      ],
      "metadata": {
        "id": "Op3_ZuSse-gq"
      }
    }
  ]
}