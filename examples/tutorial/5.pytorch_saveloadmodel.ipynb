{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOTrEo/xJ7Qo/d8M5qxTimm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Saving, loading and running model predictions in PyTorch"],"metadata":{"id":"h49O7YxYPMmZ"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"z7aC0BPiPHL7","executionInfo":{"status":"ok","timestamp":1703126750040,"user_tz":-780,"elapsed":350,"user":{"displayName":"Max Dang Vu","userId":"02858938018569343923"}}},"outputs":[],"source":["import torch\n","import torchvision.models as models"]},{"cell_type":"markdown","source":["We can store the learned model parameters from training in an internal state dictionary. We call this \"state_dict\"."],"metadata":{"id":"OMmVXJW5PXxd"}},{"cell_type":"code","source":["# save model (can convert into a function)\n","model = models.vgg16(weights='IMAGENET1K_V1')\n","torch.save(model.state_dict(), 'model_weights.pth')"],"metadata":{"id":"frV3Z-QdPWIj","executionInfo":{"status":"ok","timestamp":1703126754479,"user_tz":-780,"elapsed":4080,"user":{"displayName":"Max Dang Vu","userId":"02858938018569343923"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["We load model weights by creating an instance of the model class first, then load the model parameters. This is because the class defines the structure of the network."],"metadata":{"id":"QT7L-hTIQMlt"}},{"cell_type":"code","source":["# load model (can convert into a function)\n","model = models.vgg16()\n","model.load_state_dict(torch.load('model_weights.pth'))\n","\n","# make sure we call this before inferencing:\n","# set dropout and batch normalisation layers to evaluation model to achieve consistent results\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HFeaShg8Pstg","executionInfo":{"status":"ok","timestamp":1703126757829,"user_tz":-780,"elapsed":3365,"user":{"displayName":"Max Dang Vu","userId":"02858938018569343923"}},"outputId":"1c2d95f3-c3f1-4591-a47c-9a593fb79bba"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["We can also save the model class structure with the actual trained model itself by passing 'model' into the saving function."],"metadata":{"id":"j-gn933TQs0d"}},{"cell_type":"code","source":["torch.save(model, 'model.pth')\n","model = torch.load('model.pth')"],"metadata":{"id":"REDDV3qAQeb_","executionInfo":{"status":"ok","timestamp":1703126760188,"user_tz":-780,"elapsed":2373,"user":{"displayName":"Max Dang Vu","userId":"02858938018569343923"}}},"execution_count":7,"outputs":[]}]}